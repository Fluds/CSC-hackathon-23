{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade wandb -q\n",
    "!pip install pytorch-msssim -q"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-05T19:33:38.466840Z",
     "iopub.execute_input": "2023-07-05T19:33:38.467412Z",
     "iopub.status.idle": "2023-07-05T19:34:01.317935Z",
     "shell.execute_reply.started": "2023-07-05T19:33:38.467357Z",
     "shell.execute_reply": "2023-07-05T19:34:01.316654Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n\u001B[0m\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n\u001B[0m",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import wandb\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-05T19:34:01.321305Z",
     "iopub.execute_input": "2023-07-05T19:34:01.321979Z",
     "iopub.status.idle": "2023-07-05T19:34:01.332713Z",
     "shell.execute_reply.started": "2023-07-05T19:34:01.321934Z",
     "shell.execute_reply": "2023-07-05T19:34:01.331634Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Setups"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# user_secrets = UserSecretsClient()\n",
    "# wandb_api = user_secrets.get_secret(\"wandb_api\")\n",
    "\n",
    "# # Wandb\n",
    "# wandb.init(entity='upscale-dudes', project='csc-hackathon-2023')\n",
    "# wandb_logger = WandbLogger(entity='upscale-dudes', project=\"csc-hackathon-2023\")\n",
    "\n",
    "# Dataset paths\n",
    "# Train\n",
    "train_hr_path = '/kaggle/input/fairface-lq-10/train/256_256'\n",
    "train_lr_path = '/kaggle/input/fairface-lq-10/train/32_32'\n",
    "# Validation\n",
    "val_hr_path = '/kaggle/input/fairface-lq-10/validation/256_256'\n",
    "val_lr_path = '/kaggle/input/fairface-lq-10/validation/32_32'\n",
    "# Test\n",
    "test_hr_path = '/kaggle/input/fairface-lq-10/test/256_256'\n",
    "test_lr_path = '/kaggle/input/fairface-lq-10/test/32_32'\n",
    "\n",
    "BATCH_SIZE = 256"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-05T19:34:01.336795Z",
     "iopub.execute_input": "2023-07-05T19:34:01.337614Z",
     "iopub.status.idle": "2023-07-05T19:34:01.346702Z",
     "shell.execute_reply.started": "2023-07-05T19:34:01.337578Z",
     "shell.execute_reply": "2023-07-05T19:34:01.345479Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data modules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class UpscalingDataset(Dataset):\n",
    "    def __init__(self, lr_folder, hr_folder):\n",
    "        self.hr_folder = hr_folder\n",
    "        self.lr_folder = lr_folder\n",
    "        self.hr_images = sorted(os.listdir(hr_folder))\n",
    "        self.lr_images = sorted(os.listdir(lr_folder))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_img_name = self.hr_images[index]\n",
    "        lr_img_name = self.lr_images[index]\n",
    "\n",
    "        hr_img_path = os.path.join(self.hr_folder, hr_img_name)\n",
    "        lr_img_path = os.path.join(self.lr_folder, lr_img_name)\n",
    "\n",
    "        hr_img = Image.open(hr_img_path).convert('RGB')\n",
    "        lr_img = Image.open(lr_img_path).convert('RGB')\n",
    "        lr_img = np.array(lr_img, dtype=np.float32)\n",
    "        hr_img = np.array(hr_img, dtype=np.float32)\n",
    "        lr_img /= 255.\n",
    "        hr_img /= 255.\n",
    "        lr_img = lr_img.transpose([2, 0, 1])\n",
    "        hr_img = hr_img.transpose([2, 0, 1])\n",
    "\n",
    "        return torch.tensor(lr_img, dtype=torch.float), torch.tensor(hr_img, dtype=torch.float)\n",
    "\n",
    "\n",
    "class UpscalingDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.upscaling_train = UpscalingDataset(train_lr_path, train_hr_path)\n",
    "            self.upscaling_val = UpscalingDataset(val_lr_path, val_hr_path)\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.upscaling_test = UpscalingDataset(test_lr_path, test_hr_path)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.upscaling_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.upscaling_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.upscaling_test, batch_size=self.batch_size)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-05T19:34:01.348070Z",
     "iopub.execute_input": "2023-07-05T19:34:01.348641Z",
     "iopub.status.idle": "2023-07-05T19:34:01.374868Z",
     "shell.execute_reply.started": "2023-07-05T19:34:01.348607Z",
     "shell.execute_reply": "2023-07-05T19:34:01.373614Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Custom model template"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# class UpscalingModel(pl.LightningModule):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         # Initialize your model here\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Forward pass implementation should go here\n",
    "#         pass\n",
    "    \n",
    "#     def calculate_metrics(self, high_res, low_res):\n",
    "#         mse_loss = F.mse_loss(high_res, low_res)\n",
    "#         psnr = 10 * torch.log10(1 / mse_loss)\n",
    "#         ssim_val = ssim(high_res, low_res, data_range=1.0, size_average=True)\n",
    "#         return {'mse': mse_loss, 'psnr': psnr, 'ssim': ssim_val}\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         # Training step implementation should go here        \n",
    "#         # self.log_dict({f'train_{k}': v for k, v in metrics.items()})\n",
    "#         pass\n",
    "\n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         # Validation step implementation should go here\n",
    "#         # self.log_dict({f'val_{k}': v for k, v in metrics.items()})\n",
    "#         pass\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         # Define your optimizer and learning rate scheduler here\n",
    "#         pass\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-05T19:34:01.378021Z",
     "iopub.execute_input": "2023-07-05T19:34:01.378744Z",
     "iopub.status.idle": "2023-07-05T19:34:01.393890Z",
     "shell.execute_reply.started": "2023-07-05T19:34:01.378707Z",
     "shell.execute_reply": "2023-07-05T19:34:01.392819Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BICUBIC interpolation model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_msssim import ssim\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "class UpscalingDNN(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        self.interp = nn.Upsample((256, 256), mode='bilinear', align_corners=False)\n",
    "        self.learning_rate = 1e-3\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return self.interp(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        lr_img, hr_img = batch\n",
    "        out = self(lr_img)\n",
    "        metrics = self.calculate_metrics(hr_img, out)\n",
    "        self.log_dict({f'train_{k}': v for k, v in metrics.items()}, on_step=True, on_epoch=True)\n",
    "        return metrics['mse']\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        lr_img, hr_img = batch\n",
    "        out = self(lr_img)\n",
    "        metrics = self.calculate_metrics(hr_img, out)\n",
    "        self.log_dict({f'val_{k}': v for k, v in metrics.items()}, on_step=True, on_epoch=True)\n",
    "        if self.current_epoch % 2 == 0:  # Log images every 5 epochs\n",
    "            # Convert tensors to PIL Images\n",
    "            hr_img = to_pil_image(hr_img[0])\n",
    "            lr_img = to_pil_image(lr_img[0])\n",
    "            out = to_pil_image(out[0])\n",
    "            # Log images to wandb\n",
    "            self.logger.experiment.log({\n",
    "                \"hr_images\": wandb.Image(hr_img),\n",
    "                \"lr_images\": wandb.Image(lr_img),\n",
    "                \"out_images\": wandb.Image(out),\n",
    "            })\n",
    "            \n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         lr_img, hr_img = batch\n",
    "#         out = self(lr_img)\n",
    "#         metrics = self.calculate_metrics(hr_img, out)\n",
    "#         self.log_dict({f'val_{k}': v for k, v in metrics.items()}, on_step=True, on_epoch=True)\n",
    "\n",
    "    def calculate_metrics(self, high_res, low_res):\n",
    "        mse_loss = F.mse_loss(high_res, low_res)\n",
    "        psnr = 10 * torch.log10(1 / mse_loss)\n",
    "        ssim_val = ssim(high_res, low_res, data_range=1.0)\n",
    "        return {'mse': mse_loss, 'psnr': psnr, 'ssim': ssim_val}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-05T19:34:01.397695Z",
     "iopub.execute_input": "2023-07-05T19:34:01.397991Z",
     "iopub.status.idle": "2023-07-05T19:34:01.424177Z",
     "shell.execute_reply.started": "2023-07-05T19:34:01.397967Z",
     "shell.execute_reply": "2023-07-05T19:34:01.422910Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Custom callbacks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_mse',  # Specify the validation loss to monitor\n",
    "    dirpath='/kaggle/working/models/',  # Directory where the models will be saved\n",
    "    filename='upscaling-{epoch:02d}-{val_mse:.3f}-{val_psnr:.3f}',  # Template for the saved model's name\n",
    "    save_top_k=1,  # Save only the best model\n",
    "    mode='min',  # Minimize validation loss\n",
    ")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-05T19:34:01.427761Z",
     "iopub.execute_input": "2023-07-05T19:34:01.428522Z",
     "iopub.status.idle": "2023-07-05T19:34:01.437527Z",
     "shell.execute_reply.started": "2023-07-05T19:34:01.428484Z",
     "shell.execute_reply": "2023-07-05T19:34:01.436401Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Wandb\n",
    "wandb.init(entity='upscale-dudes', project='csc-hackathon-2023')\n",
    "wandb_logger = WandbLogger(entity='upscale-dudes', project=\"csc-hackathon-2023\")\n",
    "\n",
    "# Prepare data\n",
    "data_module = UpscalingDataModule(BATCH_SIZE)\n",
    "\n",
    "# Define your model\n",
    "model = UpscalingDNN()\n",
    "\n",
    "# Fit the model\n",
    "trainer = pl.Trainer(max_epochs=5, callbacks=[checkpoint_callback], logger=wandb_logger)  # use wandb_logger for Weights & Biases logging\n",
    "trainer.fit(model, data_module)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-05T19:34:01.438677Z",
     "iopub.execute_input": "2023-07-05T19:34:01.438999Z",
     "iopub.status.idle": "2023-07-05T19:37:45.038086Z",
     "shell.execute_reply.started": "2023-07-05T19:34:01.438968Z",
     "shell.execute_reply": "2023-07-05T19:37:45.033851Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:uxyvwyqm) before initializing another..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "VBox(children=(Label(value='2.858 MB of 2.858 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fde207bd070d4dc0bfeca4bd60a1ebcf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▃▃▃▅▅▅▁▁▃▃▃▅▅▅▆▆███</td></tr><tr><td>train_mse_epoch</td><td>█▂▂▆▂▂▁▁</td></tr><tr><td>train_mse_step</td><td>█▃█▃▁</td></tr><tr><td>train_psnr_epoch</td><td>▁▅▆▂▅▆▇█</td></tr><tr><td>train_psnr_step</td><td>▁▅▁▆█</td></tr><tr><td>train_ssim_epoch</td><td>▁▆▇▃▆▇▇█</td></tr><tr><td>train_ssim_step</td><td>▁▅▁▄█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▃▁▁▄▄▅▁▁▁▅▅▁▁▂▂▃▁▁▁▄▅▁▁▁▅▅▁▁▇▇▇▁▂▂█</td></tr><tr><td>val_mse_epoch</td><td>█▅▃█▅▂▁▁</td></tr><tr><td>val_mse_step</td><td>██▆▅▅▄▃▄▃▇█▆▅▅▄▃▃▂▂▂▁▂▂▁</td></tr><tr><td>val_psnr_epoch</td><td>▁▃▅▁▃▆▇█</td></tr><tr><td>val_psnr_step</td><td>▁▁▂▃▃▄▄▄▅▁▁▂▃▃▄▅▅▆▆▆▇▇▇█</td></tr><tr><td>val_ssim_epoch</td><td>▁▄▆▁▅▅▆█</td></tr><tr><td>val_ssim_step</td><td>▁▁▃▄▃▅▅▄▆▂▁▃▄▄▆▄▄▆▅▅▇▆▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_mse_epoch</td><td>0.01284</td></tr><tr><td>train_mse_step</td><td>0.01306</td></tr><tr><td>train_psnr_epoch</td><td>18.92031</td></tr><tr><td>train_psnr_step</td><td>18.84143</td></tr><tr><td>train_ssim_epoch</td><td>0.48983</td></tr><tr><td>train_ssim_step</td><td>0.49093</td></tr><tr><td>trainer/global_step</td><td>169</td></tr><tr><td>val_mse_epoch</td><td>0.01167</td></tr><tr><td>val_mse_step</td><td>0.00949</td></tr><tr><td>val_psnr_epoch</td><td>19.33227</td></tr><tr><td>val_psnr_step</td><td>20.22917</td></tr><tr><td>val_ssim_epoch</td><td>0.51807</td></tr><tr><td>val_ssim_step</td><td>0.56939</td></tr></table><br/></div></div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">treasured-silence-1</strong> at: <a href='https://wandb.ai/upscale-dudes/csc-hackathon-2023/runs/uxyvwyqm' target=\"_blank\">https://wandb.ai/upscale-dudes/csc-hackathon-2023/runs/uxyvwyqm</a><br/>Synced 6 W&B file(s), 57 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20230705_192644-uxyvwyqm/logs</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:uxyvwyqm). Initializing new run:<br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.5"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20230705_193401-r07k4drh</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/upscale-dudes/csc-hackathon-2023/runs/r07k4drh' target=\"_blank\">colorful-shadow-2</a></strong> to <a href='https://wandb.ai/upscale-dudes/csc-hackathon-2023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/upscale-dudes/csc-hackathon-2023' target=\"_blank\">https://wandb.ai/upscale-dudes/csc-hackathon-2023</a>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/upscale-dudes/csc-hackathon-2023/runs/r07k4drh' target=\"_blank\">https://wandb.ai/upscale-dudes/csc-hackathon-2023/runs/r07k4drh</a>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9512cd8ddbff462d9e7829821a143116"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train template"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# # Prepare data\n",
    "# data_module = UpscalingDataModule(BATCH_SIZE)\n",
    "\n",
    "# # Define your model\n",
    "# model = UpscalingModel()\n",
    "\n",
    "# # Fit the model\n",
    "# trainer = pl.Trainer(max_epochs=10, logger=wandb_logger)\n",
    "# trainer.fit(model, data_module)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-05T19:37:45.039759Z",
     "iopub.execute_input": "2023-07-05T19:37:45.040130Z",
     "iopub.status.idle": "2023-07-05T19:37:45.044821Z",
     "shell.execute_reply.started": "2023-07-05T19:37:45.040096Z",
     "shell.execute_reply": "2023-07-05T19:37:45.043850Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  }
 ]
}
