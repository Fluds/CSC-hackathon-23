{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pytorch_msssim","metadata":{"execution":{"iopub.status.busy":"2023-07-08T17:08:49.599155Z","iopub.execute_input":"2023-07-08T17:08:49.599509Z","iopub.status.idle":"2023-07-08T17:09:01.697118Z","shell.execute_reply.started":"2023-07-08T17:08:49.599482Z","shell.execute_reply":"2023-07-08T17:09:01.695930Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pytorch_msssim\n  Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from pytorch_msssim) (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_msssim) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_msssim) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_msssim) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_msssim) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_msssim) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->pytorch_msssim) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->pytorch_msssim) (1.3.0)\nInstalling collected packages: pytorch_msssim\nSuccessfully installed pytorch_msssim-1.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#from kaggle_secrets import UserSecretsClient\n\nimport numpy as np\nimport os\nimport wandb\nfrom PIL import Image\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom pytorch_lightning import LightningModule, Trainer\nfrom pytorch_msssim import ssim\nfrom torchvision.transforms.functional import to_pil_image","metadata":{"execution":{"iopub.status.busy":"2023-07-08T17:09:01.699190Z","iopub.execute_input":"2023-07-08T17:09:01.699573Z","iopub.status.idle":"2023-07-08T17:09:14.692889Z","shell.execute_reply.started":"2023-07-08T17:09:01.699532Z","shell.execute_reply":"2023-07-08T17:09:14.691960Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# user_secrets = UserSecretsClient()\n# wandb_api = user_secrets.get_secret(\"wandb_api\")\n\n# # Wandb\n# wandb.init(entity='upscale-dudes', project='csc-hackathon-2023')\n# wandb_logger = WandbLogger(entity='upscale-dudes', project=\"csc-hackathon-2023\")\n\n# Dataset paths\n# Train\n#train\n#train\ntrain_hr_path = '/kaggle/input/fairfaceupsample/train/256_256'\ntrain_lr_path = '/kaggle/input/fairfaceupsample/train/32_32'\n\n#val\nval_hr_path = '/kaggle/input/fairface-lq-10/fairface_lq-lite_v2/validation/256_256'\nval_lr_path = '/kaggle/input/fairface-lq-10/fairface_lq-lite_v2/validation/32_32'\n\n#test\ntest_hr_path = '/kaggle/input/fairface-lq-10/fairface_lq-lite_v2/test/256_256'\ntest_lr_path = '/kaggle/input/fairface-lq-10/fairface_lq-lite_v2/test/32_32'\nBATCH_SIZE = 16","metadata":{"execution":{"iopub.status.busy":"2023-07-08T17:11:00.974795Z","iopub.execute_input":"2023-07-08T17:11:00.975154Z","iopub.status.idle":"2023-07-08T17:11:00.980908Z","shell.execute_reply.started":"2023-07-08T17:11:00.975126Z","shell.execute_reply":"2023-07-08T17:11:00.979992Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class UpscalingDataset(Dataset):\n    def __init__(self, lr_folder, hr_folder):\n        self.hr_folder = hr_folder\n        self.lr_folder = lr_folder\n        self.hr_images = sorted(os.listdir(hr_folder))\n        self.lr_images = sorted(os.listdir(lr_folder))\n\n    def __len__(self):\n        return len(self.hr_images)\n\n    def __getitem__(self, index):\n        hr_img_name = self.hr_images[index]\n        lr_img_name = self.lr_images[index]\n        hr_img_path = os.path.join(self.hr_folder, hr_img_name)\n        lr_img_path = os.path.join(self.lr_folder, lr_img_name)\n\n        hr_img = Image.open(hr_img_path).convert('RGB')\n        lr_img = Image.open(lr_img_path).convert('RGB')\n\n        lr_img = np.array(lr_img, dtype=np.float32)\n        hr_img = np.array(hr_img, dtype=np.float32)\n        \n        lr_img /= 255.\n        hr_img /= 255.\n        lr_img = lr_img.transpose([2, 0, 1])\n        hr_img = hr_img.transpose([2, 0, 1])\n\n        return torch.tensor(lr_img, dtype=torch.float), torch.tensor(hr_img, dtype=torch.float)\n\n\nclass UpscalingDataModule(pl.LightningDataModule):\n    def __init__(self, batch_size):\n        super().__init__()\n        self.batch_size = batch_size\n\n    def setup(self, stage=None):\n        # Assign train/val datasets for use in dataloaders\n        if stage == 'fit' or stage is None:\n            self.upscaling_train = UpscalingDataset(train_lr_path, train_hr_path)\n            self.upscaling_val = UpscalingDataset(val_lr_path, val_hr_path)\n        # Assign test dataset for use in dataloader(s)\n        if stage == 'test' or stage is None:\n            self.upscaling_test = UpscalingDataset(test_lr_path, test_hr_path)\n\n    def train_dataloader(self):\n\n        return DataLoader (self.upscaling_train, batch_size=self.batch_size,shuffle = True)\n\n    def val_dataloader(self):\n        return DataLoader(self.upscaling_val, batch_size=self.batch_size,shuffle = True)\n\n    def test_dataloader(self):\n        return DataLoader(self.upscaling_test, batch_size=self.batch_size,shuffle = True)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T17:11:02.219346Z","iopub.execute_input":"2023-07-08T17:11:02.219699Z","iopub.status.idle":"2023-07-08T17:11:02.232681Z","shell.execute_reply.started":"2023-07-08T17:11:02.219672Z","shell.execute_reply":"2023-07-08T17:11:02.231801Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"UDLRN(Shuffle)","metadata":{}},{"cell_type":"code","source":"class ConvReluBlock(nn.Module):\n    def __init__(self, channelsin, channelsout):\n        super(ConvReluBlock, self).__init__()\n        self.conv_block = nn.Sequential(\n            nn.Conv2d(channelsin, channelsout, kernel_size = 3, stride=1, padding = 1, dilation = 1),\n            nn.ReLU(),\n            nn.Conv2d(channelsout, channelsout, kernel_size = 3, stride=1, padding = 1, dilation = 1),\n            nn.ReLU()\n        )\n\n    def forward(self, x):\n        res = x\n        x = self.conv_block(x)\n        out = x + res\n        return out\n\nclass AttentionLikeBlock(nn.Module):\n    def __init__(self, channel, reduct=4):\n        super(AttentionLikeBlock, self).__init__()\n        self.globPool = nn.AdaptiveAvgPool2d(1)\n        self.convo1 = nn.Sequential(\n            nn.Conv2d(channel, channel//reduct, kernel_size = 3, stride=1, padding = 3, dilation=3),\n            nn.ReLU()\n        )\n        self.convo2 = nn.Sequential(\n            nn.Conv2d(channel, channel//reduct, kernel_size = 3, stride=1, padding = 5, dilation=5),\n            nn.ReLU()\n        )\n        self.convo3 = nn.Sequential(\n            nn.Conv2d(channel, channel//reduct, kernel_size = 3, stride=1, padding = 7, dilation=7),\n            nn.ReLU()\n        )\n\n        self.convsig = nn.Sequential(\n            nn.Conv2d((channel//reduct)*3,channel , kernel_size = 3, stride=1, padding = 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        gd = self.globPool(x)\n        r3 = self.convo2(gd)\n        r5 = self.convo2(gd)\n        r7 = self.convo2(gd)\n        gp = torch.cat([r3,r5,r7], 1)\n        sigm = self.convsig(gp)\n        out = x*sigm\n        return out\n\nclass DRLM(nn.Module):\n    def __init__(self, channelsin, chanelsout, deapth=3):\n        super(DRLM, self).__init__()\n        self.baseblock = nn.ModuleList([ConvReluBlock(channelsin*(2**i), chanelsout*(2**i)) for i in range(deapth)])\n        self.compresion = nn.Sequential(\n            nn.Conv2d(channelsin*(2** len(self.baseblock)),chanelsout, kernel_size=1, padding=0, stride=1, dilation=1),\n            nn.ReLU()\n        )\n        self.attention = AttentionLikeBlock(channelsin)\n\n       \n        \n    def forward(self, x):\n        longCon = x\n        #print(x.size())\n        for i, _ in enumerate(self.baseblock):\n            skip = x\n            x = self.baseblock[i](x)\n            x = torch.cat((x, skip),1)\n        x = self.compresion(x)\n        x = self.attention(x)\n        out  = longCon + x\n        return out\n\nclass BaseBLock(nn.Module):\n    def __init__(self, channels, channelsoutin):\n        super(BaseBLock, self).__init__()\n        self.drlm = DRLM(channels, channels)\n        self.convoDown = nn.Sequential(\n            nn.Conv2d(channelsoutin, channels, kernel_size=3, padding=1, stride=1, dilation=1),\n            nn.ReLU()\n        ) \n\n    def forward(self, x, cat):\n        x = self.drlm(x)\n        cat = torch.cat((x,cat),1)\n        x = self.convoDown(cat)\n        return(x, cat)\n\n\n\nclass CascadeBlock(nn.Module):\n    def __init__(self, channels, deapth=3 ):\n        super(CascadeBlock, self).__init__()\n        self.baseBlocks = nn.ModuleList([BaseBLock(channels, channels*(i+2)) for i in range(deapth)])\n    \n    def forward(self, x):\n        shortSkip = x\n        cat = x\n        for  i, _ in enumerate(self.baseBlocks):\n            x, cat =  self.baseBlocks[i](x, cat)\n        out = x+shortSkip\n        return out\n\nclass UpsampleBlock(nn.Module):\n    def __init__(self, n_channels):#, scale):\n        super(UpsampleBlock, self).__init__()\n        self.upscale = nn.Sequential(\n            nn.Conv2d(n_channels, n_channels*8, 3, 1, 1),\n            nn.ReLU(inplace=True),\n            nn.PixelShuffle(8)\n        )\n\n    def forward(self, x):\n        #print(x.size())\n        x = self.upscale(x)\n        return x\n\nclass UDLRN(LightningModule):\n    def __init__(self, channels, deapth=6, channelsin=3):\n        super(UDLRN, self).__init__()\n        self.learning_rate = 1e-3\n        self.inputConv = nn.Sequential(\n            nn.Conv2d(channelsin, channels, kernel_size = 3, stride=1, padding = 1, dilation = 1),\n            nn.ReLU()\n        )\n        self.cascadeBLocks = nn.ModuleList([CascadeBlock(channels) for i in range(deapth)])\n        self.upscale  = UpsampleBlock(channels*8)\n        #self.upscale = ESPCN(channels,channelsin,channels, 8)\n        self.tail = nn.Conv2d(channels, 3, 3, 1, 1)\n\n    def forward(self, x):\n        x = self.inputConv(x)\n        longSkip = x\n        longcat = [x]\n        for  i, _ in enumerate(self.cascadeBLocks):\n            x =  self.cascadeBLocks[i](x)\n            longcat.append(x)\n        x = x + longSkip\n        longcat.append(x)\n        out = torch.cat(longcat, 1)\n        out = self.upscale(out)\n        out = self.tail(out)\n        out = (torch.tanh(out)+1)/2\n        return out\n    \n    def training_step(self, batch, batch_idx):\n        lr_img, hr_img = batch\n        out = self(lr_img)\n        metrics = self.calculate_metrics(hr_img, out)\n        self.log_dict({f'train_{k}': v for k, v in metrics.items()}, on_step=True, on_epoch=True)\n        return metrics['mse']\n    \n    def validation_step(self, batch, batch_idx):\n        lr_img, hr_img = batch\n        out = self(lr_img)\n        metrics = self.calculate_metrics(hr_img, out)\n        self.log_dict({f'val_{k}': v for k, v in metrics.items()}, on_step=True, on_epoch=True)\n        if self.current_epoch % 5 == 0:  # Log images every 5 epochs\n            # Convert tensors to PIL Images\n            hr_img = to_pil_image(hr_img[0])\n            lr_img = to_pil_image(lr_img[0])\n            out = to_pil_image(out[0])\n            # Log images to wandb\n            self.logger.experiment.log({\n                \"hr_images\": wandb.Image(hr_img),\n                \"lr_images\": wandb.Image(lr_img),\n                \"out_images\": wandb.Image(out),\n            })\n    def test_step(self, batch, batch_idx):\n        lr_img, hr_img = batch\n        out = self(lr_img)\n        metrics =self.calculate_metrics(hr_img, out)\n        self.log_dict({f'val_{k}': v for k, v in metrics.items()}, on_step=True, on_epoch=True)\n            \n#     def validation_step(self, batch, batch_idx):\n#         lr_img, hr_img = batch\n#         out = self(lr_img)\n#         metrics = self.calculate_metrics(hr_img, out)\n#         self.log_dict({f'val_{k}': v for k, v in metrics.items()}, on_step=True, on_epoch=True)\n\n    def calculate_metrics(self, high_res, low_res):\n        mse_loss = F.mse_loss(high_res, low_res)\n        psnr = 10 * torch.log10(1 / mse_loss)\n        ssim_val = ssim(high_res, low_res, data_range=1.0)\n        return {'mse': mse_loss, 'psnr': psnr, 'ssim': ssim_val}\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n\n\n        scheduler = {\n            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min'),\n            'monitor': 'val_mse', \n        }\n\n        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_mse\"}\n\n\n\nmodel = UDLRN(channels = 64)\ninput_tensor = torch.rand(1, 3, 32, 32)\noutput_tensor  = model( input_tensor)\nprint(\"Output shape:\", output_tensor.shape)  # Output shape: torch.Size([1, 3, 256, 256])\n\n\n       \n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T17:12:10.463889Z","iopub.execute_input":"2023-07-08T17:12:10.464335Z","iopub.status.idle":"2023-07-08T17:12:11.859862Z","shell.execute_reply.started":"2023-07-08T17:12:10.464306Z","shell.execute_reply":"2023-07-08T17:12:11.858860Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Output shape: torch.Size([1, 3, 256, 256])\n","output_type":"stream"}]},{"cell_type":"code","source":"from pytorch_lightning.callbacks import ModelCheckpoint\n\n# Define the checkpoint callback\ncheckpoint_callback = ModelCheckpoint(\n    monitor='val_mse',  # Specify the validation loss to monitor\n    dirpath='/kaggle/working/models/',  # Directory where the models will be saved\n    filename='upscaling-{epoch:02d}-{val_mse:.4f}-{val_psnr:.3f}',  # Template for the saved model's name\n    save_top_k=1,  # Save only the best model\n    mode='min',  # Minimize validation loss\n    \n)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T17:12:14.923189Z","iopub.execute_input":"2023-07-08T17:12:14.923582Z","iopub.status.idle":"2023-07-08T17:12:14.932553Z","shell.execute_reply.started":"2023-07-08T17:12:14.923551Z","shell.execute_reply":"2023-07-08T17:12:14.931351Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data_module = UpscalingDataModule(BATCH_SIZE)\ndata_module.setup()","metadata":{"execution":{"iopub.status.busy":"2023-07-08T17:12:16.911322Z","iopub.execute_input":"2023-07-08T17:12:16.911679Z","iopub.status.idle":"2023-07-08T17:12:18.581162Z","shell.execute_reply.started":"2023-07-08T17:12:16.911652Z","shell.execute_reply":"2023-07-08T17:12:18.580202Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Wandb\nwandb.init(entity='upscale-dudes', project='csc-hackathon-2023')\nwandb_logger = WandbLogger(entity='upscale-dudes', project=\"csc-hackathon-2023\")","metadata":{"execution":{"iopub.status.busy":"2023-07-08T17:12:27.199214Z","iopub.execute_input":"2023-07-08T17:12:27.199586Z","iopub.status.idle":"2023-07-08T17:13:16.484394Z","shell.execute_reply.started":"2023-07-08T17:12:27.199559Z","shell.execute_reply":"2023-07-08T17:13:16.483531Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230708_171244-t6q6ttc0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/upscale-dudes/csc-hackathon-2023/runs/t6q6ttc0' target=\"_blank\">lively-vortex-72</a></strong> to <a href='https://wandb.ai/upscale-dudes/csc-hackathon-2023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/upscale-dudes/csc-hackathon-2023' target=\"_blank\">https://wandb.ai/upscale-dudes/csc-hackathon-2023</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/upscale-dudes/csc-hackathon-2023/runs/t6q6ttc0' target=\"_blank\">https://wandb.ai/upscale-dudes/csc-hackathon-2023/runs/t6q6ttc0</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n  rank_zero_warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define your model\nmodel = UDLRN(channels = 64)\n\n# Fit the model\ntrainer = pl.Trainer(max_epochs=100, callbacks=[checkpoint_callback], logger=wandb_logger)  # use wandb_logger for Weights & Biases logging\ntrainer.fit(model, data_module)\n#trainer.test(model, data_module) # with fine-tuning","metadata":{"execution":{"iopub.status.busy":"2023-07-08T17:13:29.878851Z","iopub.execute_input":"2023-07-08T17:13:29.879772Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:480: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n  rank_zero_warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49d78ca154f647378a5b6a709d8d6fff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('model', 'zip', '/kaggle/working/')\n%cd /kaggle/working\nfrom IPython.display import FileLink\nFileLink(r'model.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''model = MyLightningModule.load_from_checkpoint(\"/path/to/checkpoint.ckpt\")\ntrainer.test(model, data_module) # with fine-tuning'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}